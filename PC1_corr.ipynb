{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load model weights.\n",
    "USE_FULL_1900_DIM_MODEL = False # if True use 1900 dimensional model, else use 64 dimensional one.\n",
    "\n",
    "# Set seeds\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "if USE_FULL_1900_DIM_MODEL:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/1900_weights/ 1900_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler1900 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./1900_weights\"\n",
    "    \n",
    "else:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler64 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./64_weights\"\n",
    "    \n",
    "    \n",
    "def nonpad_len(batch):\n",
    "    nonzero = batch > 0\n",
    "    lengths = np.sum(nonzero, axis=1)\n",
    "    return lengths    \n",
    "    \n",
    "    \n",
    "# Create babbler.\n",
    "batch_size = 64\n",
    "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)\n",
    "\n",
    "\n",
    "hidden_vals_filename = 'sarkisyan_final_hidden_vals.txt'\n",
    "seqs_filename = 'sarkisyan_filtered_seqs.txt'\n",
    "brightness_filename = 'sarkisyan_filtered_brightness.txt'\n",
    "\n",
    "\n",
    "if os.path.exists(seqs_filename) and os.path.exists(brightness_filename):\n",
    "    seqs = np.loadtxt(seqs_filename)\n",
    "    brightness = np.loadtxt(brightness_filename)\n",
    "else:\n",
    "    # Load sarkisyan dataset\n",
    "    sarkisyan = pd.read_csv('sarkisyan.csv')\n",
    "    sequences = []\n",
    "    brightness = []\n",
    "    stop_codon_cnt = 0\n",
    "    for i, row in sarkisyan.iterrows():\n",
    "        seq = row.seq.strip('*')\n",
    "        if b.is_valid_seq(seq) and len(seq) < 275: \n",
    "            sequences.append(b.format_seq(seq))\n",
    "            brightness.append(row.medianBrightness)\n",
    "        else:\n",
    "            if '*' in seq:\n",
    "                stop_codon_cnt += 1\n",
    "            else:\n",
    "                print('Invalid seq', seq)\n",
    "    seqs = np.stack(sequences)\n",
    "    brightness = np.array(brightness)[:, None]\n",
    "    print('Formatted %d sequences. Discarded %d with stop codon.' % (seqs.shape[0], stop_codon_cnt))\n",
    "    np.savetxt(seqs_filename, seqs)\n",
    "    np.savetxt(brightness_filename, brightness)\n",
    "\n",
    "    \n",
    "if os.path.exists(hidden_vals_filename):\n",
    "    final_hidden_vals = np.loadtxt(hidden_vals_filename)\n",
    "else:\n",
    "    final_hidden_op, x_placeholder, batch_size_placeholder, seq_length_placeholder, initial_state_placeholder = (\n",
    "        b.get_rep_ops())\n",
    "    final_hidden_vals = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        n_batches = int(seqs.shape[0] / batch_size)\n",
    "        leftover = seqs.shape[0] % batch_size\n",
    "        n_batches += int(bool(leftover))\n",
    "        for i in range(n_batches):\n",
    "            if i == n_batches - 1:\n",
    "                batch = seqs[-batch_size:]\n",
    "            else:\n",
    "                batch = seqs[i*batch_size:(i+1)*batch_size]\n",
    "            length = nonpad_len(batch)\n",
    "            final_hidden_ = sess.run(\n",
    "                final_hidden_op,\n",
    "                feed_dict={\n",
    "                    x_placeholder: batch,\n",
    "                    batch_size_placeholder: batch.shape[0],\n",
    "                    seq_length_placeholder: length,\n",
    "                    initial_state_placeholder:b._zero_state\n",
    "                })\n",
    "            if i == n_batches - 1:\n",
    "                final_hidden_vals.append(final_hidden_[-leftover:])\n",
    "            else:\n",
    "                final_hidden_vals.append(final_hidden_)\n",
    "\n",
    "    final_hidden_vals = np.concatenate(final_hidden_vals, axis=0)\n",
    "    np.savetxt(hidden_vals_filename, final_hidden_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
